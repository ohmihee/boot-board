카프카는 링크드인에서 개발된 플랫폼으로 오픈소스로 구성되어 있다. 기 카프카 이전에는 데이터 처리를 위해 redist나 rabbit Q 를 사용
카프카는 데이터 처리를 중앙집중화한 것이다. 카프카 이전의 앤드투앤드 연결 방식의 아키텍쳐 구조로 인해 데이터 연동의 복잡성 증가, 확장 어려움

# Kafka broker & Cluster
: 카프카 애플리케이션 서버 중 1대, 3대 이상의 브로커로 클로스터를 구성한다.
n개 브로커 중 1대는 컨트롤러 기능 수행
컨트롤러 : 각 브로커에게 담당파티션 할당 수행, 브로커 정상 동작 모니터링 관리, 누가 컨트롤러 인지 주키퍼에 저장
# 주키퍼
메타데이터(브로커 id, 컨트롤러 id 등) 저장하며, 관리

객체를 프로듀서에서 컨슈머로 전달하기 위해 Kafka 내부에 byte 형태로 저장할 수 있도록 직렬화/역직렬화하여 사용
카프카 내부적으로는 데이터를 byte 형태로 저장하기 때문에, 프로듀서와 컨슈머에서는 직렬화와 역직렬화 과정이 필요하다.
// StringSerializer, ShortSerializer 등의 직렬화 클래스를 통해 가능
new ProducerRecord<String, String>("topic","key","message");
ConsumerRecords<String, String> records = consumer.poll(1000);
for (ConsumerRecord<String, String> record: records) {}

- 토픽의 각 파티션마다 고유한 오프셋을 가지며, 메시지 처리 순서를 파티션 별로 유지 관리된다.
- 프로듀서는 레코드를 생성하여 브로커로 전송
- 컨슈머는 브로커로부터 레코드를 요청하여 가져간다.
- 메시지가 저장될 때는 세그먼트 파일이 열려 있음.
- 세그먼트는 시간 또는 크기 기준으로 닫힘
- 세그먼트가 닫힌 이후 일정 시간(또는 용량)에 따라 삭제 또는 압축된다.
- 파티션 개수는 반드시 컨슈머 개수보다 적어야 한다. 같은 컨슈머 그룹 기준인 경우.
- 목적에 따라 컨슈머 그룹을 분리하여 관리할 경우, 특정 컨슈머 그룹에 장애가 발생하더라도 다른 컨슈머 그룹에는 영향을 주지 않는다.
- 특징

1. 고가용성
2. 뛰어난 확장성
   데이터의 중요성이 커지는 시점에서 카프카는 앞으로 사용이 더욱 증가할 추세.
   listener를 통해 producer 로부터 요청을 받아 처리하는 구조,
   producer와 consumer는 카프카에서 제공하는 api로 구현된 어플리케이션을 의미한다.
   broker가 되는 각각의 KafkaServer는 자신의 식별자로 broker.id를 부여받게 되며, producer로부터 생성된 메시지를 저장할 위치정보와 클러스터 메타
   정보를
   저장 및 관리할 Zookeeper 연결 정보가 지정된다.
   Pub-Sub 모델
   : 발행자가 Topic에 메시지를 전송하면, 해당 토픽을 구독한 구독자가 메시지를 받는다.
   카프카의 특징

1. 여러 전달자가 동시 전송, 여러 소비자가 동시 읽기 가능
2. 전송된 메시지는 일정 기간 파일 형태로 저장되어 처리 속도, 장애 복구 가능
3. 시스템 트래픽이 높아지면 브로커를 추가해 클러스터 확장 가능
4. 처리 속도 저하의 경우 소비자/생산자를 축하해 처리량을 늘릴 수 있음
5. 컨슈머를 그룹으로 묶어 프로듀서에서 보내는 속도와 읽는 속도 균형 맞추기 가능.

* 카프카 오프셋

- 컨슈머는 메시지를 가져올 때마다 오프셋 정보를 커밋함으로써 기존에 어디 위치까지 가져왔는지 알 수 있다.
- 파티션이 여러 개인 상태에서 프로슈머가 파티션 키를 지정하지 않은 경우, 메시지는 Round-robin 방식으로 각 파티션에 분배된다.
- 메세지의 순서는 동일 파티션 내 오프셋을 기준으로 보장된다.
- 고가용성 및 데이터 유식을 막기 위해 replication을 수행한다.
- 원본 파티션이 리더 파티션이 되고, 복제 파티션의 경우 팔로워 파티션이 된다.
- 리터 파티션에 문제가 발생하는 경우, 복제 파티션 중 하나가 새로운 리더 파티션이 된다.


* ISR(= In Sync Replica)

- 리더와 팔로워로 이루어진 리플리케이션 그룹을 의미한다.
- Read/Write 권한은 오직 리더 파티션에게만 주어지며, 팔로워 파티션은 리더 파티션의 데이터를 복제하여 동기화하는 역할을 한다.

- 팔로워 파티션에 문제가 발생한 경우, 가용성에 영향을 주므로, 팔로워 파티션에 문제가 생격 일정 주기동안 요청이 오지 않는 경우 ISR그룹에서 추방된다.
  ** 컨슈머 그룹
  동일 토픽에 대해 여러 컨슈머가 메시지를 가져갈 수 있도록 컨슈머 그룹이라는 기능을 제공한다.
  여러 개의 토픽에서 하나의 컨슈머가 메시지를 가져감으로 인해 메시지 처리 속도가 느려질 경우, 컨슈머를 확장하여 하나의 파티션 당 하나의 컨슈머가 연결되도록 하여, 메시지 처리
  속도를 높일 수 있다.
  단 컨슈머의 수가 파티션의 수를 초과할 수는 없다. 예를 들어 3개의 파티션에 4개의 컨슈머가 붙을 수는 없다.
  카프카의 경우 데이터를 디스크에 저장하기 때문에, 특정 컨슈머가 데이터를 가져간다고 해도, 메시지가 사라지지 않고, 계속해서 남아있는다.
  카프카는 동일 파티션 내에서 메시지 처리 순서를 보장한다. 오프셋값을 통해 unique 하게 순차적으로 증가하는 값을 메시지에 부여하기 때문에 이를 통해 순서를 보장한다.
  하지만 파티션이 여러 개인 경우 전체 메시지 순서를 보장할 수 없게 된다. 따라서 전체 메시지의 순서를 보장하고자 하는 경우에는 하나의 파티션을 활용해야 한다.
- 카프카는 컨슈머가 브로커에서 직접 데이터를 가져오는 pull 방식으로 동작한다. 메시지를 pull 방식으로 가져오므로, 메시지를 쌓아두었다가 주기적으로 처리하는 batch
  consumer 구현이 가능하다.
- 카프카는 실시간 로그 처리에 특화되어 설계된 메시징 시스템으로, 기존 메시징 시스템 대비 TPS가 매우 우수하다.
- 카프카는 메시지를 batch 형태로 처리하는 것이 가능하다.
- 메시지를 기본적으로 파일 시스템에 저장한다.
- 카프카는 페이지 캐시 기능을 사용하여 매우 높은 처리 속도를 가진다. (메모리 영역에 어플리케이션이 사용하는 부분을 할당하고 남은 잔여 메모리를 캐시로 전환하여 디스크 접근을
  최소화해 I/O 성능을 향상시키는 메모리 영익이다.)
- 카프카는 JVM에서 돌아가기 때문에 메모리 할당 영역을 자바처럼 설정할 수 있다.
- 카프카는 수평적 확장을 위해 클러스터를 구성한다.
- 카프카는 여러 브로커들의 클러스터링을 위해 아파치 주키퍼를 사용한다.
- 카프카 클러스터 위에서 프로듀서가 전송한 메시지는 중복 저장 되어 장애 상황에서도 고 가용성을 보장하게 된다.
- 프로듀서가 메시지를 카프카 클러스터 전송하면, 브로커는 또 다른 브로커에게 프로듀서의 메시지를 중복해서 저장한다.
- 카프카의 토픽에 여러 프로듀서가 동시에 메시지 전송 가능. 또한 카프카 토픽의 메시지를 여러 컨슈머들이 동시에 읽어 가는 것도 가능 (다중 프로듀서, 다중 컨슈머 지원)
- 카프카는 프로듀서가 생성한 메시지를 브로커가 위치한 서버의 파일 시스템에 저장한다. 때문에 컨슈머는 프로듀서가 생성한 메시지를 바로 바로 가져가지 않아도, 메시지는 보관함에
  그대로 남아있으며,
  컨슈머가 토픽의 메시지를 가져단다고 해도, 해당 메시지가 사라지지 않으며, 카프카에 설정한 내용에 따라 메시지가 삭제된다.
- 카프카 클러스터는 운영 중에 확장이 용이하도록 설계되었다.
- 때문에 일반적으로 데이터 파이프라인을 구축한 초창기 적은 수의 브로커들로 클러스터를 운영하다가 시스템 트래픽이 높아지면 브로커를 추가해서 클러스터를 확장할 수 있다.
- 프로듀서와 컨슈머도 증가시키는 것이 가능하다.
- 컨슈머 그룹에 컨슈머를 추가할 수 있으며, 컨슈머 그룹에 컨슈머가 추가되면 컨슈머의 파티션 소유권이 재분배되는 리밸런스 과정을 거쳐 컨슈머 그룹에 속한 컨슈머들이 고를게
  파티션을 할당받게 된다.
- 카프카 토픽은 내부에서 파티션이라는 세분화된 단위로 나뉘어 저장되게 된다.
- 카프카는 대용량 실시간 로그 처리에 특화되어 있다.
- 카프카는 불필요한 기능을 제외하고, 내부적으로 배치처리 분산 처리와 같은 다양한 기법을 사용해 처리량을 최대로 끌어냈다.
- 카프카는 pull 방식으로 되어 있어, 브로커가 컨슈머의 처리량을 고민할 필요가 없다. 컨슈머 스스로 자신이 처리 가능한 만큼의 메시지를 브로커에서 가져와 처리하기 때문이다.
- 카프카는 높은 메시지 처리량과 낮은 지연율을 지닌다.
- 데이터를 클러스터화된 여러 서버에 저장하기 때문에, 하나의 서버에 문제가 생겨도 복구가 가능하도록 설계되었다.
- 카프카는 기본적으로 Pub/Sub 기반의 Event Driven Architecture 로 구성되어 있다.

주요요소

- 브로커 :  카프카 애플리케이션이 설치된 서버 또는 Node를 의미
- 카프카 or 카프카 클러스터 : 여러 대의 브로커를 구성한 클러스터
- 주키퍼(zookeeper) : 카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당
- 프로듀서 :  카프카로 메시지를 보내는 역할
- 컨슈머 :  카프카 메시지를 가져오는 역할
- 토픽 : 카프카 내애서 메시지를 구분할 때 사용되는 단위
- 파티션 : 병렬 처리 + 고성능을 위해 하나의 토픽을 여러 개로 나눈 단위
- 세그먼트 : 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일을 의미(메시지 저장 단위)
- 메시지 or 레코드 : 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각
- 리플리케이션 : 카프카의 안정성 유지를 위해 사용

* 리플리케이션(replication -> 복제?)
  메시지를 여러 위치에 분산 저장하여, 하나의 카프카에 문제가 발생하더라도 안정성을 유지할 수 있도록 도움을 준다.
    - kafka-topics.sh 명령어에서 --replication-factor 인자를 통해 설정 가능하다.
      예를 들어 해당 인자의 값을 3으로 설정하면 3개의 브로커에 동일한 메시지를 저장하게 된다.
    - 주의점은 replication-factor의 경우 현재 구성된 카프카 브로커의 개수보다 클 수 없다는 것이다. 즉 3개의 브로커 존재 시 4개의 replication
      factor를 설정하는 것은 불가능하다.
    - topic이 아닌 토픽의 파티션을 기준으로 replication 된다.
    - replication factor 수가 많아지면 안전성은 높아지지만, 리소스를 (디스크 공간을) 많이 차지하게 된다.
    - replication 기능은 토픽 자체가 아닌 토픽의 파티션을 복제한다.

* 파티션
    - 토픽에서 메시지 처리 시 높은 성능 및 병렬성 제공을 위해 사용한다.
    - 하나의 토픽은 여러 개의 파티션을 가진다.
    - 파티션의 수를 늘리는 것은 가능하나, 줄이는 것을 불가능하다.
    - key 값을 기준으로 하여 카프카 자체에서 hashing 하여 파티션 밸런스 조정이 이루어진다.
    - key 값 없이 데이터를 전송한 경우에는 라운드 로빈 방식으로 메시지를 저장한다.
    - 파티션에서 메시지가 저장되는 위치를 offset이라 하며, 64bit 정수 단위로 index를 가진다.
      offset을 통해 컨슈머는 데이터를 읽을 때마다 커밋하여, 마지막에 읽은 위치를 알 수 있다.
      .
* 세그먼트
    - 카프카는 프로듀서에서 보낸 메시지를 브로커의 로컬에 저장하며, 이 단위를 세그먼트라고 한다. 하나의 파티션에는 여러 개의 세그먼트가 존재할 수 있다.
    - /data/kafka-logs/ 경로에 저장이 된다.

- 분산 시스템은 네트워크 상에 연결된 컴퓨터들의 그룹을 말한다.

* 페이지 캐시
    - 물리 메모리 중 애플리케이션이 사용하지 않는 일분 잔여 메모리를 활용하여 페이지 캐싱용으로 사용 가능.

- 카프카는 메시지를 실시간으로 전송하지 않고, 배치로 전송하는 것이 가능하다.
- 카프카는 압축 전송을 지원한다.

* 주키퍼(Zookeeper)
    - 주키퍼는 znode를 이용해 카프카의 메타정보를 기록하여 관리한다.

(다양한 이벤트들을 카프카를 통해 받아 AWS S3, Elasticsearch 등에 전달)

Message Queue 특징

- 비동기 : Queue에 데이터를 보관하기 때문에 나중에 데이터 처리 가능
- 비동조 : 애플리케이션과 분리 가능
- 탄력성 : 일부 실패 시에도 전체에 영향을 받지 않는다.
- 과잉 : 실패할 경우 재실행 가능하다.
- 보증 :  작업이 처리된 걸 확인할 수 있다.
- 확장성 : 다수의 프로세스들이 큐에 메시지를 보낼 수 있다.

카프카 사용시 주의할 브로커 버전과 클라이언트의 버전이 맞는지 호환성을 확인해주어야 한다.

# Broker

카프카가 설치되어 있는 서버 단위를 의미한다. 일반적으로 3개 이상의 브로커로 구성하여 사용하는 것이 권장된다.<br/>

# Replication => 복제

파티션의 복제를 의미한다. replication이 1이라는 것은 파티션이 1개만 존재함을 의미하며, replication이 2라면 파티션은 원본 1개와 복제본 1개로 되어 있음을
의미한다. replication이 3개라면 파티션은 원본 1개와 복제본 2개로 이루어진다. 당연한 말이지만 원본은 오직 1개만 존재한다. 때문에 replicaton 개수가
증가한다는 것은 복제본이 증가함을 의미한다. 다만 주의할 점을 replication의 개수는 브로커의 개수에 의해 제한된다. 즉 브로커의 개수가 3개라면 replication의
개수도 3개를 초과할 수 없음을 의미한다.
이 때 원본이 되는 데이터가 담기는 파티션을 reader 파티션이라고 하고, 복제본 파티션은 Follower 파티션이라고 한다.
Replication은 파티션의 고가용성을 위해 사용된다. 예를 들어 브로커가 3개인 카프카에서 replication이 1이고, partion이 1인 topic이 존재한다고 가정할
때, 해당 브로커가 어떠한 이유로 사용불가한 상태가 된다면, 해당 파티션은 복구가 불가능해진다. 이때 복제본인 replication이 존재한다면, 원본 파티션에 문제가
발생하더라도, 복제본을 통해 복구가 가능하다. Reader 파티션의 지위는 Follower 파티션이 승계받게 된다.
기본적으로 프로듀서가 생성하여 전송한 데이터는 리더 파티션에 전송되며, Follower 파티션들은 Leader 파티션의 데이터를 복제해가는 것이다.
프로듀서에는 ack 라는 상세 옵션이 존재하는데 ack를 통해 고가용성을 유지할 수 있다. 이는 파티션의 replication과 관련이 있는데, ack는 0,1,all 중 1개로
설정할 수 있는데 0인 경우 프로듀서는 Leader 파티션에 데이터를 전송하고, 응답값은 받지 않는다. 그렇기 때문에 Leader 파티션에 데이터가 정상적으로 전송되었는지 확인할
수 없다.
1인 경우 Leader 파티션에 데이터가 온전히 전송되면 응답값을 받는다. 이때 Leader 파티션에 전송된 데이터가 Follower 파티션들에도 온전히 복제되었는지는 보장하지
않는다.
all인 경우에는 Leader 파티션 뿐 아니라, Follower 파티션에도 모두 데이터가 온전히 복제되면 응답값을 전송한다. all의 경우 데이터의 안정성은 보장되지만,
데이터가 온전히 복제되었는지까지 확인하는 과정이 추가되기 때문에 현저히 속도가 느려지게 된다.
즉 속도 면에서는 0 > 1 > all 순서가 되며, 데이터 안정성 측면에서는 반대로 all > 1 > 0 순서가 된다.
replication의 수가 많아질수록 데이터의 안정성이 높아지기는 하나, 지나치게 replication이 많아지면 브로커의 리소스 사용량이 증가하게 된다. 때문에 적절한

# ISR(=In Sync Replica)

Leader 파티션과 Follower 파티션을 모두 합쳐서 ISR 이라고 한다.

만약 파티션이 1개이고 replication이 1인 topic이 존재하고, 브로커가 3대라면 브로커 3대 중 1대에 해당 토픽 정보가 저장된다.

# Producer

데이터를 생성하는 producer는 send() 메서드를 통해 토픽에 데이터를 발행한다.</br>
토픽에 파티션이 여러 개일 때 데이터 전송 시 키를 지정하지 않는 경우 라운드 로빈으로 데이터가 들어가게 된다.
파티션에 들어간 데이터는 파티션 내에서 고유한 번호를 부여받게 되는데, 이를 offset이라고 한다. offset은 토픽별로 그리고 파티션별로 별개로 지정된다.
이는 컨슈머가 데이터를 어느 지점까지 읽었는지 확인하는 용도로 사용된다. </br>
컨슈머가 데이터를 읽기 시작하면 offset을 커밋하게 된다. 이에 대한 정보는 카프카의 __consumer_offset 토픽에 저장된다.
</br> 예를 들어 컨슈머가 파티션이 2개인 click_log 라는 토픽에서 데이터를 구독하고 있다고 할때, 컨슈머가 데이터를 가져갈 때마다 offset 정보가 저장되게 된다.
이 경우에 컨슈머에 문제가 발생하더라도 토픽의 어느 데이터까지 읽었는지에 대한 정보가 카프카 __consumer_offset에 담겨 있기 때문에 컨슈머를 재실행하여 정상이 되면
이전의 데이터를 읽었던 부분부터 데이터 처리를 다시 할 수 있다. 즉 컨슈머에 문제가 발생하더라도 __consumer_offset 토픽에 저장된 offset 정보를 바탕으로 시작
위치 복구가 가능해진다.

# Consumer

아파치 카프카 메시징 시스템의 특징 중 하나는 컨슈머가 데이터를 가져가면 큐에 쌓인 데이터가 사라지는 기존의 다른 메시징 시스템과 달리 카프카의 경우는 특정 컨슈머가 큐에 쌓인
데이터를 가져간다고 해도 메시지가 사라지지 않고 남아있는다.
컨슈머가 데이터를 가져오는 것을 폴링이라고 한다.
컨슈머의 역할

1. topic의 파티션으로부터 데이터 polling
2. Partition offset 위치 기록(commit)
3. Consemer group을 통해 병렬 처리
   : 파티션 개수에 따라 컨슈머를 여러개 만들면 병령 처리가 가능하기 때문에 더욱 빠른 속도로 데이터 처리가 가능하다.

## 컨슈머 사용

컨슈머 사용을 위해서는 kafka-clients라는 라이브러리를 추가해주어야 한다.

## 컨슈머의 갯수?

파티션이 두개인 토픽이 있다고 가정할때

컨슈머가 1개인 경우 2개의 파티션에서 데이터를 가져간다.</br>
컨슈머가 2개인 경우 각 컨슈머가 각각의 파티션을 할당하여 데이터를 가져가서 처리한다.
컨슈머가 3개인 경우 파티션과 컨슈머가 1대 1 할당되고 남은 1개의 컨슈머는 할당될 파티션이 없기 때문에 동작하지 않게 된다.
즉 컨슈머 개수는 파티션 개수보다 적거나 같아야 한다.

- 각기 다른 컨슈머 그룹에 속한 컨슈머들은 다른 컨슈머 그룹에 영향을 미치지 않는다.
  컨슈머 그룹별로 토픽별로 offset을 나누어 저장하기 때문이다.

카프카 실습
카

- brew install kafka
- 카프카 실행을 위해서 주키퍼를 실행시킨다. brew install kafka로 설치 시 주키퍼도 함께 설치된다.
- brew services start zookeeper
- brew services start kafka
- brew info kafka를 통해 설치된 카프카에 대한 정보를 볼 수 있다.
- 토픽 생성 ./kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 -partitions
  1 --topic mihee
  // replication-factor가 1개이고 파티션이 1개인 토픽 생성
- 토픽에 데이터 전송 ./kafka-console-producer --broker-list localhost:9092 --topic mihee
- > hello world
- 토픽 데이터 읽기 ./kafka-console-consumer --bootstrap-server localhost:9092 --topic mihee
  --from-beginning


* 카프카 lag : 컨슈머가 마지막으로 읽은 offset과 프로듀서가 마지막으로 넣은 offset의 차이

처리 과정
프로듀서 -> 브로커 -> 컨슈머
단위
브로커 > 토픽 > 파티션(리더, 팔로워, 리플리케이션) > 세그먼트

listener를 통해 producer 로부터 요청을 받아 처리하는 구조,
producer와 consumer는 카프카에서 제공하는 api로 구현된 어플리케이션을 의미한다.
broker가 되는 각각의 KafkaServer는 자신의 식별자로 broker.id를 부여받게 되며, producer로부터 생성된 메시지를 저장할 위치정보와 클러스터 메타 정보를
저장 및 관리할 Zookeeper 연결 정보가 지정된다.
Pub-Sub 모델
: 발행자가 Topic에 메시지를 전송하면, 해당 토픽을 구독한 구독자가 메시지를 받는다.
카프카의 특징

1. 여러 전달자가 동시 전송, 여러 소비자가 동시 읽기 가능
2. 전송된 메시지는 일정 기간 파일 형태로 저장되어 처리 속도, 장애 복구 가능
3. 시스템 트래픽이 높아지면 브로커를 추가해 클러스터 확장 가능
4. 처리 속도 저하의 경우 소비자/생산자를 축하해 처리량을 늘릴 수 있음
5. 컨슈머를 그룹으로 묶어 프로듀서에서 보내는 속도와 읽는 속도 균형 맞추기 가능.

* 카프카 오프셋

- 컨슈머는 메시지를 가져올 때마다 오프셋 정보를 커밋함으로써 기존에 어디 위치까지 가져왔는지 알 수 있다.
- 파티션이 여러 개인 상태에서 프로슈머가 파티션 키를 지정하지 않은 경우, 메시지는 Round-robin 방식으로 각 파티션에 분배된다.
- 메세지의 순서는 동일 파티션 내 오프셋을 기준으로 보장된다.
- 고가용성 및 데이터 유식을 막기 위해 replication을 수행한다.
- 원본 파티션이 리더 파티션이 되고, 복제 파티션의 경우 팔로워 파티션이 된다.
- 리터 파티션에 문제가 발생하는 경우, 복제 파티션 중 하나가 새로운 리더 파티션이 된다.

* ISR(= In Sync Replica)

- 리더와 팔로워로 이루어진 리플리케이션 그룹을 의미한다.
- Read/Write 권한은 오직 리더 파티션에게만 주어지며, 팔로워 파티션은 리더 파티션의 데이터를 복제하여 동기화하는 역할을 한다.

- 팔로워 파티션에 문제가 발생한 경우, 가용성에 영향을 주므로, 팔로워 파티션에 문제가 생격 일정 주기동안 요청이 오지 않는 경우 ISR그룹에서 추방된다.
  ** 컨슈머 그룹
  동일 토픽에 대해 여러 컨슈머가 메시지를 가져갈 수 있도록 컨슈머 그룹이라는 기능을 제공한다.
  여러 개의 토픽에서 하나의 컨슈머가 메시지를 가져감으로 인해 메시지 처리 속도가 느려질 경우, 컨슈머를 확장하여 하나의 파티션 당 하나의 컨슈머가 연결되도록 하여, 메시지 처리
  속도를 높일 수 있다.
  단 컨슈머의 수가 파티션의 수를 초과할 수는 없다. 예를 들어 3개의 파티션에 4개의 컨슈머가 붙을 수는 없다.
  카프카의 경우 데이터를 디스크에 저장하기 때문에, 특정 컨슈머가 데이터를 가져간다고 해도, 메시지가 사라지지 않고, 계속해서 남아있는다.
  카프카는 동일 파티션 내에서 메시지 처리 순서를 보장한다. 오프셋값을 통해 unique 하게 순차적으로 증가하는 값을 메시지에 부여하기 때문에 이를 통해 순서를 보장한다.
  하지만 파티션이 여러 개인 경우 전체 메시지 순서를 보장할 수 없게 된다. 따라서 전체 메시지의 순서를 보장하고자 하는 경우에는 하나의 파티션을 활용해야 한다.
- 카프카는 컨슈머가 브로커에서 직접 데이터를 가져오는 pull 방식으로 동작한다. 메시지를 pull 방식으로 가져오므로, 메시지를 쌓아두었다가 주기적으로 처리하는 batch
  consumer 구현이 가능하다.
- 카프카는 실시간 로그 처리에 특화되어 설계된 메시징 시스템으로, 기존 메시징 시스템 대비 TPS가 매우 우수하다.
- 카프카는 메시지를 batch 형태로 처리하는 것이 가능하다.
- 메시지를 기본적으로 파일 시스템에 저장한다.
- 카프카는 페이지 캐시 기능을 사용하여 매우 높은 처리 속도를 가진다. (메모리 영역에 어플리케이션이 사용하는 부분을 할당하고 남은 잔여 메모리를 캐시로 전환하여 디스크 접근을
  최소화해 I/O 성능을 향상시키는 메모리 영익이다.)
- 카프카는 JVM에서 돌아가기 때문에 메모리 할당 영역을 자바처럼 설정할 수 있다.
- 카프카는 수평적 확장을 위해 클러스터를 구성한다.
- 카프카는 여러 브로커들의 클러스터링을 위해 아파치 주키퍼를 사용한다.
- 카프카 클러스터 위에서 프로듀서가 전송한 메시지는 중복 저장 되어 장애 상황에서도 고 가용성을 보장하게 된다.
- 프로듀서가 메시지를 카프카 클러스터 전송하면, 브로커는 또 다른 브로커에게 프로듀서의 메시지를 중복해서 저장한다.
- 카프카의 토픽에 여러 프로듀서가 동시에 메시지 전송 가능. 또한 카프카 토픽의 메시지를 여러 컨슈머들이 동시에 읽어 가는 것도 가능 (다중 프로듀서, 다중 컨슈머 지원)
- 카프카는 프로듀서가 생성한 메시지를 브로커가 위치한 서버의 파일 시스템에 저장한다. 때문에 컨슈머는 프로듀서가 생성한 메시지를 바로 바로 가져가지 않아도, 메시지는 보관함에
  그대로 남아있으며,
  컨슈머가 토픽의 메시지를 가져단다고 해도, 해당 메시지가 사라지지 않으며, 카프카에 설정한 내용에 따라 메시지가 삭제된다.
- 카프카 클러스터는 운영 중에 확장이 용이하도록 설계되었다.
- 때문에 일반적으로 데이터 파이프라인을 구축한 초창기 적은 수의 브로커들로 클러스터를 운영하다가 시스템 트래픽이 높아지면 브로커를 추가해서 클러스터를 확장할 수 있다.
- 프로듀서와 컨슈머도 증가시키는 것이 가능하다.
- 컨슈머 그룹에 컨슈머를 추가할 수 있으며, 컨슈머 그룹에 컨슈머가 추가되면 컨슈머의 파티션 소유권이 재분배되는 리밸런스 과정을 거쳐 컨슈머 그룹에 속한 컨슈머들이 고를게
  파티션을 할당받게 된다.
- 카프카 토픽은 내부에서 파티션이라는 세분화된 단위로 나뉘어 저장되게 된다.
- 카프카는 대용량 실시간 로그 처리에 특화되어 있다.
- 카프카는 불필요한 기능을 제외하고, 내부적으로 배치처리 분산 처리와 같은 다양한 기법을 사용해 처리량을 최대로 끌어냈다.
- 카프카는 pull 방식으로 되어 있어, 브로커가 컨슈머의 처리량을 고민할 필요가 없다. 컨슈머 스스로 자신이 처리 가능한 만큼의 메시지를 브로커에서 가져와 처리하기 때문이다.
- 카프카는 높은 메시지 처리량과 낮은 지연율을 지닌다.
- 데이터를 클러스터화된 여러 서버에 저장하기 때문에, 하나의 서버에 문제가 생겨도 복구가 가능하도록 설계되었다.
- 카프카는 기본적으로 Pub/Sub 기반의 Event Driven Architecture 로 구성되어 있다.

* 프로듀서 주요 옵션

- bootstrap.servers
  카프카 클러스터에 연결하기 위한 호스트와 포트 정보 목록을 의미한다.
  host:port, host:port, host:port
  일반적으로 여러 개의 호스트를 통해 접근할 수 있도록 하는데, 이는 특정 호스트에 문제가 발생하더라도 다른 호스트를 통해 접속할 수 있도록 하기 위함이다.
- acks
  프로듀서가 카프카 토픽의 리더에게 메시지 전송 후, 요청을 완료하였다고 판단하기 위해 사용되는 옵션이다.
  총 (0, 1, -1) 세 가지 옵션이 있다.
  0 프로듀서가 카프카 서버에 메시지 전송 후 아무런 응답을 기다리지 않는다. (대신에 빠른 속도)
  1 프로듀서가 카프카 서버에 메시지 전송 후 리더 파티션에 데이터가 온전히 저장되면 응답을 받는다. 팔로워 파티션에 리더 파티션의 데이터가 복제되기 이전에 문제가 발생하는 경우
  어느 정도의 데이터 손실이 가능하다.
  -1 프로듀서가 카프카 서버에 메시지 전송 후 리더 파티션은 물론, 팔로워 파티션에도 데이터가 동기화되면 응답을 받는다.
  프로듀서는 응답을 받지 못하면 다시 카프카 서버에 메시지를 전송함으로서 데이터 유실 가능섬을 줄일 수 있다.
- 브로커의 설정은 환경설정 파일인 server.properties에서 변경할 수 있다.
  acks 설정에서 중요한 것은 리플리케이션의 설정도 함께 설정해주어야 한다는 것이다.
  acks가 all 즉 -1 로 설정되어 있다고 하더라도 리플리케이션 설정이 1로 되어 있는 경우 결과적으로 acks=1처럼 동작하기 때문이다.
  // https://goodgid.github.io/Kafka-Send-Message-Mehotd-2/
  데이터 처리 속도 0 > 1 >  -1
  데이터 손실 가능성 0 > 1 > -1
  아파치 카프카 문서에서 권장하는 손실없는 메시지 전송을 위한 설정 조건은 아래와 같다.
  ming.insync.replication 가 3이면 acks를 보내기 전에 최소 3개의 리플리케이션을 유지하는지 확인한다.
  Producer : acks = all
  Broker : min.insync.replicas = 2
  // min.insync.replicas = 3로 설정을 하게 되면, 브로커 하나만 다운되더라도 서비스의 장애가 발생하게 된다.
  Topic : Replication Factor = 3

* 컨슈머 주요 옵션

- 컨슈머는 데이터를 가져오기 위해, 파티션 리더에게 데이터를 요청하여,데이터를 가져오는데 이때 모든 요청은 오프셋에 기록된다.
  (컨슈머는 오프셋 기록을 통해 이미 가져온 메시지를 다시 가져올 수 도 있다.)
- fetch.min.bytes : 한 번에 가져올 수 있는 최소 데이터 사이즈로, 설정한 사이즈보다 작은 경우 요청에 대해 응답하지 않고 데이터가 누적될 때까지 기다린다.
- fetch.max.wait.ms : fetch.min.bytes에 의해 설정된 데이터보다 적은 경우, 요청에 응답을 기다리는 최대 시간
- fetch.max.bytes : 한 번에 가져올 수 있는 최대 데이터 사이즈
- session.timeout.ms : 컨슈머와 브로커 사이의 세션 타임 아웃 시간, 즉 컨슈머가 브로커에서 데이터를 가져간 후 응답이 올 때까지 기다리는 시간
  브로커가 컨슈머가 살아있는 것으로 판단하는 시간, 컨슈머가 그룹 코디네이터에게 하트비트를 보내지 않고, session.timeout.ms 가 지나면, 해당 컨슈머는 종료되거나
  장애가 발생한 것으로 판단하고 컨슈머 그룹은 리밸런스를 시도한다.
  session.timeout.ms를 지나치게 낮게 설정하면 컨슈머에서 데이터 가져가기를 실패한 경우 이를 빨리 감지할 수 있는 반면 컨슈머가 정상적으로 메시지를 처리하는
  과정에서 Timeout이 발생하며,
  파티션 리밸런싱 과정이 일어나고, 정삭적으로 처리한 데이터를 중복하여 가져오게 된다.
  반대로 session.timeout.ms를 지나치게 높게 설정한 경우에는 실제 오류를 감지하는데 시간이 소요될 수 있다.
- heartbeat.interval.ms : 그룹 코디네이터에게 얼마나 자주
- max.poll.records : 단일 호출 poll에 대한 최대 레코드 수를 조정한다.
- max.poll.interval.ms
- enable.auto.commit : 백그라운드로 주기적으로 오프셋을 커밋한다.
- auto.commit.interval.ms : 주기적으로 오프셋을 커밋하는 시간
- auto.offset.reset : 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않는 경우 리셋 시 설정
  earliest, latest, none 세 가지 옵션이 존재한다.
  earliest: 가장 초기의 오프셋값으로 설정
  latest: 가장 마지막 오프셋값으로 설정
  none: 이전 오프셋값을 찾지 못하면 에러 발생
- group.id : 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자
- request.timeout.ms : 요청에 대해 응답을 기다리는 최대 시간

* 컨슈머 종류

- 올드 컨슈며
  컨슈머의 오프셋을 주키퍼의 Znode에 저장하는 방식을 지원한다.
- 뉴 컨슈머
  컨슈머의 오프셋 저장을 카프카의 토픽에 저장하는 방식으로 변경되었다.

- 기본적으로 컨슈머 그룹 안에서 컨슈머들은 메시지를 가져오고 있는 토픽의 파티션에 대해 소유권을 공유한다.

* 컨슈머 그룹
  하나의 토픽에 여러 컨슈머 그룹이 동시에 접속해 메시지를 가져올 수 있다.
  기존에 메모리에 메시지를 저장하는 메시징 플랫폼의 경우 컨슈머가 메시지를 가져가면 큐에서 메시지가 삭제되어 다른 컨슈머가 가져갈 수 없지만, 카프카의 경우 파일에 메시지를
  저장하기 때문에 컨슈머가 메시지를 가져가도 다른 컨슈머가 메시지를 가져갈 수 있다.
  프로듀서가 토픽에 전송하는 메시지의 수가 컨슈머가 토픽에서 메시지를 가져가는 속도보다 빠른 경우 컨슈머를 확장하여 성능을 높일 수 있다.
  단순하게 컨슈머만 확장하면 기존 컨슈머의 오프셋 정보와 새로 추가된 컨슈머의 오프셋 정보가 뒤섞여 메시지들의 순서 보장이 깨진다.
  때문에 카프카에서는 동일한 토픽에 대해 여러 컨슈머가 메시지를 가져갈 수 있도록 컨슈머 그룹이라는 기능을 제공한다.
  동일한 컨슈머 그룹 내 컨슈머가 추가되면 리밸런스가 일어나며, 컨슈머 02, 03은 기존 컨슈머 01이 가져가고 있던 파티션 1과 2에서 메시지를 가져가게 된다.
  하나의 파티션에 하나의 컨슈머만 연결된다. (즉 하나의 컨슈머에 여러 개의 파티션이 연결되는 것은 가능)
  컨슈머 그룹마다 각자의 오프셋을 별도로 관리한다. 때문에 하나의 토픽에 N개의 컨슈머 그룹이 연결되어 있어도, 다른 컨슈머 그룹에 영향없이 메시지를 가져갈 수 있다.
  컨슈머가 poll을 호출할 때마다 컨슈머 글부은 카프카에 저장되어 있는 아직 읽지 않은 메시지를 가져온다.
  컨슈머 그룹의 컨슈머들은 각각의 파티션에 자신기 가져간 메시지의 위치 정보를 기록한다.


* 리벨런스
  하나의 컨슈머 그룹 내에서 토픽에 대한 소유권을 재조정하는 과정.
  컨슈머 그룹 내에서 리벨런스가 일어나면 토픽의 각 파티션마다 하나의 컨슈머가 연결된다.
  리밸런스를 통해 컨슈머 그룹에 컨슈머를 확장하고, 제거할 수 있어 높은 가용성과 확장성을 확보할 수 있다.
  리밸런스가 동안 일시적으로 컨슈머는 메시지를 가져올 수 없게 된다. 즉 리벨런스가 발생하는 동안에는 컨슈머 그룹 전체가 일시적으로 작업을 정지하게 된다.
  리벨런스가 끝나면 컨슈머들은 각자 담당하고 있는 파티션으로부터 메시지를 가져온다.


* 메시지 손실이 발생 가능한 경우

- acks가 0인 경우
  데이터가
- ack가 1인 경우
  프로듀서가 acks=1로 토픽의 리더에게 메시지를 보낸다. -> 리더는 메시지를 받은 후 저장한다. -> 리더는 프로듀서에게 메시지를 받았다고 acks로 보낸다. ->
  팔로워들은 리더를 주기적으로 체크한다. -> 리더에 새로운 메시지가 있는 것을 확인하고 팔로워들도 저장한다.
  리더에 장애가 발생하는 경우: 리더가 프로듀서에게 메시지를 잘 받았다고 acks를 보낸 상태 -> 이후 팔로워 파티션들이 리더 파티션을 체크하면서 변경된 데이터를 동기화 이후
  리더에 문제가 생긴 상태
  -> 팔로워들은 리더로부터 데이터를 가져오지 못한다. -> 리더 파티션이 사라져서 팔로워 파티션이 리더 파티션이 되었지만 팔로워 파티션은 이전의 리더 파티션의 데이터를
  동기화하지 못한 상태로 리더가 된다.
- ack가 -1인 경우

컨슈머

- buffer.memory
- compression.type : 데이터 압축 시 타입
- retries : 전송 실패 시 데이터 재전송 횟수
- batch.size : 배치 전송 시 데이터 크기 단위 : 배치를 보내기 전 클라이언트 장애가 발생 시 배치 내에 있던 메시지는 전달되지 않는다.
- linger.ms : 배치 형태의 메시지를 보내기 전에, 추가적인 메시지들을 위해 기다리는 시간을 조정.
  단 지정된 배치 사이즈에 도달하면, 해당 옵션과 관계없이 즉시 메시지를 전송하고, 배치 사이즈에 도달하지 못한 상황일 때, linger.ms 제한 시간에 도달할 경우 메시지들을
  전송한다.
- max.request.size : 프로듀서가 보낼 수 있는 최대 메시지 바이트

주요요소

- 브로커 :  카프카 애플리케이션이 설치된 서버 또는 Node를 의미
- 카프카 or 카프카 클러스터 : 여러 대의 브로커를 구성한 클러스터
- 주키퍼(zookeeper) : 카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당
- 프로듀서 :  카프카로 메시지를 보내는 역할
- 컨슈머 :  카프카 메시지를 가져오는 역할
- 토픽 : 카프카 내애서 메시지를 구분할 때 사용되는 논리적 단위, 프로듀서와 컨슈머는 토픽 단위로 데이터를 전송하고, 가져오기 때문에, 토픽명이 중복되지 않도록 해야한다.
- 파티션 : 병렬 처리 + 고성능을 위해 하나의 토픽을 여러 개로 나눈 단위, 수평 확장이 가능한 단위
- 세그먼트 : 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일을 의미(메시지 저장 단위)
- 메시지 or 레코드 : 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각
- 리플리케이션 : 카프카의 안정성 유지를 위해 사용

* 리플리케이션(replication -> 복제?)
  메시지를 여러 위치에 분산 저장하여, 하나의 카프카에 문제가 발생하더라도 안정성을 유지할 수 있도록 도움을 준다.
    - kafka-topics.sh 명령어에서 --replication-factor 인자를 통해 설정 가능하다.
      예를 들어 해당 인자의 값을 3으로 설정하면 3개의 브로커에 동일한 메시지를 저장하게 된다.
    - 주의점은 replication-factor의 경우 현재 구성된 카프카 브로커의 개수보다 클 수 없다는 것이다. 즉 3개의 브로커 존재 시 4개의 replication
      factor를 설정하는 것은 불가능하다.
    - topic이 아닌 토픽의 파티션을 기준으로 replication 된다.
    - replication factor 수가 많아지면 안전성은 높아지지만, 리소스를 (디스크 공간을) 많이 차지하게 된다.
    - replication 기능은 토픽 자체가 아닌 토픽의 파티션을 복제한다.


* 파티션
    - 토픽에서 메시지 처리 시 높은 성능 및 병렬성 제공을 위해 사용한다.
    - 하나의 토픽은 여러 개의 파티션을 가진다.
    - 파티션의 수를 늘리는 것은 가능하나, 줄이는 것을 불가능하다.
    - 파티션의 수를 늘릴 때마다 차지하는 리소스가 증가하고, 장애 복구 시간이 증가하기 때문에, 단순히 전송 속도를 높이기 위해서만 무작정 파티션의 수를 늘리는 것은 좋지
      않다.
    - key 값을 기준으로 하여 카프카 자체에서 hashing 하여 파티션 밸런스 조정이 이루어진다.
    - key 값 없이 데이터를 전송한 경우에는 라운드 로빈 방식으로 메시지를 저장한다.
    - 파티션에서 메시지가 저장되는 위치를 offset이라 하며, 64bit 정수 단위로 index를 가진다.
      offset을 통해 컨슈머는 데이터를 읽을 때마다 커밋하여, 마지막에 읽은 위치를 알 수 있다.
    - 예를 들어 메시지를 발행하는 어플리케이션이 하나의 프로듀서가 A라는 토픽에 4개의 메시지를 전송한다고 하였을 때, 프로듀서는 순차적으로 메시지가 전송된 후 다음 메시지를
      전송할 수 있다. 만약 하나의 메시지 전송 시 1초가 발생한다면, 4개의 메시지를 보내기 위해서는 최소 4초의 시간이 필요하다.
      이때 프로듀서와 파티션의 수를 늘리면 처리 속도를 높이는게 가능하다. 각 프로듀서가 메시지를 분산하여 각 파티션에 동시에 전송한다고 했을 때, 병렬적으로 메시지를
      처리하는 것이 가능하기 때문에 데이터 전송 속도를 단축 시킬 수 있다.
    - 파티션의 수를 늘리는 것은 가능하지만, 파티션 수를 줄이기 위해서는 토픽을 삭제하는 방법 밖에는 없다.
    - 카프카에서 권장하는 파티션 수는 브로커당 2,000 개 정도이다.
    - 파티션의 Read/Write는 모두 리더 파티션에서만 발생하고, 팔로워 파티션은 리더 파티션의 데이터를 복제만 한다.
      팔로워 파티션은 리더 파티션의 저장된 데이터의 순서, 오프셋 등이 완전히 동일한 상태를 갖게 된다.
    - 팔로워는 리더를 주기적으로 체크하면서 리더파티션과의 데이터를 동기화시킨다.

~ 브로커에는 토픽이 있고, 토픽은 여러 개의 파티션으로 나뉘어 있으므로, 브로커에는 여러 개의 파티션이 존재한다.
~ 파티션은 하나의 리터 파티션과 나머지 팔로워 파티션으로 나뉘게 된다.
? 브로커가 다운되었는데 파티션의 리더가 해당 브로커에서 속해있다면, 해당 파티션은 일시적으로 사용할 수 없게 된다. 이때 카프카는 팔로워 중 하나를 리더로 이동시켜 클라이언트
요청을 처리하게 된다.
? 위와 같이 리더 파티션에 문제가 생겼을 때 팔로워 파티션을 리더 파티션으로 전화시키는 것과 같은 작업 처리를 컨트롤러가 수행하며, 컨트롤러는 카프카 클러스터 내 하나만
존재한다.

- 파티션의 수가 많을수록 파일 핸들 수가 많아지게 되어 리소스를 낭비하게 되기 때문이다.

* ISR
  현재 리플리케이션이 되고 있는 그룹을 의미한다. 즉 ISR은 데이터를 동기화하는 리더와 팔로워 파티션들로 이루어진 하나의 그룹 단위라 할 수 있다.
  리더 파티션은 주기적으로 팔로워 파티션을 체크하며, 카프카 구성 시 설정한 일정 주기만큼 팔로워 파티션으로부터 확인 요청이 오지 않는다면,
  리더는 해당 팔로워의 문제가 발생했음을 인지하고, ISR 그룹에서 문제가 발생한 팔로워 파티션을 추방시킨다.

* 컨트롤러

* 오프셋
  카프카의 경우 으포셋이라는 개념을 통해 각 파티션의 메시지 저장 위치를 기억한다.. 64비트 정수 형태로 되어 있는 오프셋은 파티션내에서 유일하고 순차적으로 증가하면 메시지
  순서를 보장한다.
  먼저 도착한 데이터일수록 0에 가깝다.
  컨슈머는 0에서부터 데이터를 가져갈 수 있으며, 데이터를 가져갈 때마다 오프셋에 이를 기록해두는데 이를 커밋이라 한다.
  .
* 세그먼트
    - 카프카는 프로듀서에서 보낸 메시지를 브로커의 로컬에 저장하며, 이 단위를 세그먼트라고 한다. 하나의 파티션에는 여러 개의 세그먼트가 존재할 수 있다.
    - /data/kafka-logs/ 경로에 저장이 된다.

- 분산 시스템은 네트워크 상에 연결된 컴퓨터들의 그룹을 말한다.

* 페이지 캐시
    - 물리 메모리 중 애플리케이션이 사용하지 않는 일분 잔여 메모리를 활용하여 페이지 캐싱용으로 사용 가능.

- 카프카는 메시지를 실시간으로 전송하지 않고, 배치로 전송하는 것이 가능하다.
- 카프카는 압축 전송을 지원한다.

* 주키퍼(Zookeeper)
    - 주키퍼는 znode를 이용해 카프카의 메타정보를 기록하여 관리한다.

- 카프카는 기존의 메시징 시스템이 메모리 기반으로 되어 있는 것과 다르게, 디스크 기반으로 이루어져 있다.
  디스크로 데이터를 저장하기 때문에, 큐에서 메시지를 가져가더라도 토픽에서 메시지가 사라지는 것이 아니라 보관 설정에 따라 일정 주기 동안 장기적으로 보관하는 것이 가능하다.
  또한 디스크로 데이터를 저장하기 때문에, 컨슈머가 데이터에 문제가 생겨 데이터를 일시적으로 가져가지 못하더라도, 디스크에 데이터가 계속 남아있기 때문에 데이터 손실의 위험이
  없다.
- 페이지 캐시라는 공간에 저장 후 지연하여 파일을 저장, 하나의 컨슈머에 읽기 요청이 왔을 때 페이지 캐시에 저장 후, 동일한 데이터 요청이 왔을 때 메모리에 적재되어 있는
  데이터를 전송
- 카프카는 Sequential IO를 이용해 디스크 읽기 속도를 증가시킨다.
- 디스크의 읽기 속도는 실제 데이터를 읽는 속도가 아니라, 데이터의 위치를 찾는 시간에 의해 디스크 읽기 속도가 지연된다.
- kafka는 데이터를 순차적으로 저장한다.
- kafka는 거대한 파일들에 데이터를 저장하고, 삭제는 그 파일의 모든 데이터가 expire 되었을 때만 진행되기 때문에, 파편화가 거의 발생하지 않는다.
-

* 카프카의 리플리케이션 (replication)
  카프카는 토픽 자체가 아닌 토픽을 구성하는 파티션의 리플리케이션 즉 복제를 통해 가용성을 보장한다.
  몇 개의 리폴리케이션을 둘 것인지를 설정하는 것이 Replication.Factor 이다.
  default.replication.factor의 값은 1로 되어 있다. 이는 복제를 하지 않고, 원본만 두는 상태이다.
  Replication.factor를 2개로 변경할 경우 1개는 원본 1개는 복제가 된다.

(다양한 이벤트들을 카프카를 통해 받아 AWS S3, Elasticsearch 등에 전달)

* 주키퍼(Zookeeper)
  주키퍼는 분산 애플리케이션을 위한 코디네이션 시스템이다.
  분산 애플리케이션이 안정적인 서비스를 할 수 있도록 분산되어 있는 각 애플리케이션의 정보를 중앙에 집중하고, 구성 관리, 구룹 관리, 네이밍 동기화 등의 서비스를 제공한다.
  주키퍼는 여러 대의 서버로 구성된 클러스터를 관리한다.
  분산 애플리케이션들은 각각 주키퍼 서버들과 연결항 상태 정보 등을 주고 받는다.
  상태 정보들은 주키퍼의 Znode로 불리는 곳에 Key-Value 형태로 저장된다.
  Znode는 데이터 변경 등에 대한 유효성 검사 등을 위해 버전 번호를 관리하게 되며, Znode의 데이터가 변경될 때마다 Znode의 버전 번호가 증가한다.
  앙상블로 구성되어 있는 주키퍼는 과반수 방식에 따라 살아 있는 노드 수가 과반수 이상 유지되면 지속적인 서비스가 가능하다.
  // https://goodgid.github.io/Zookeeper/
  분산시스템 : 같은 역할을 하는 여러 대의 서버로 이루어진 서버 그룹을 의미한다. 분산 시스템으로 되어 있는 경우, 작업에 대한 처리를 여러 서버가 분산하여 처리하기 때문에
  성능이 증가하고, 하나의 서버에 문제가 발생하더라도 다른 서버가 작업을 대신 처리할 수 있기 때문에 가용성이 높다.
  또한 시스템 확장이 필요한 경우 서버를 추가 하면 되기 때문에, 시스템 확장이 더욱 용이하다.
* 배치작업
  카프카는 작은 단위의 데이터들을 배치 작업으로 처리함으로써 I/O를 줄여 처리 속도를 높일 수 도 있다.

Message Queue 특징

- 비동기 : Queue에 데이터를 보관하기 때문에 나중에 데이터 처리 가능
- 비동조 : 애플리케이션과 분리 가능
- 탄력성 : 일부 실패 시에도 전체에 영향을 받지 않는다.
- 과잉 : 실패할 경우 재실행 가능하다.
- 보증 :  작업이 처리된 걸 확인할 수 있다.
- 확장성 : 다수의 프로세스들이 큐에 메시지를 보낼 수 있다.

카프카의 핵심요소

- Broker: 카프카 애플리케이션 서버 단위
- Topic : 데이터 분리 단위, 다수 파티션 보유
  성- Offset : 각 레코드당 파티션에 할당된 고유 번호
- Consumer : 레코드를 polling하는 애플리케이션
    - Consumer group : 다수 컨슈머 묶음
    - Consumer Offset : 특정 컨슈머가 가져간 레코드의 번호
- Producer : 레코드를 브로커로 전송하는 애플리케이션
- Replication : 파티션 복제 기능
    - ISR : 리더 + 팔로워 파티션의 sync 된 묶음
- Rack-awareness : server rack 이슈에 대응

Kafka-clients : 자바에서 카프카 플랫폼을 이용할 수 있도록 구현된 라이브러리
kafka-streams : 데이터 변환을 목적으로 사용하는 api

// server.properties 속

- broker.id : 정수로 된 브로커 번호. 클러스터 내 고유 번호로 지정
- listeners : kafka 통신에 사용되는 host:port
- advertised.listeners : kafka client 가 접속한 host:port
- log.dirs : 메시지를 저장할 디스크 디렉토리. 세그먼트가 저장됨
- log.segment.bytes : 메시지가 저장되는 파일의 크기 단위
- log.retention.ms : 메시지를 얼마나 보존할 지 지정, 닫힌 세그먼트를 처리
- zookeeper.connect :  브로커의 메타데이터를 저장하는 주키퍼의 위치
- auto.create.topics.enable : 자동 토픽 생성 여부
- num.partitions : 자동 생성된 토픽의 default partition 개수
- message.max.bytes : kafka broker에 쓰려는 메시지 최대 크기

# producer acks

- acks = 0
  가장 빠른 속도, 높은 유실 가능성
  프로듀서가 브로커와 소켓 연결을 맺어 보낸 즉시 성공으로 간주, 브로커가 정상적으로 받아서 리더 파티션에 저장했는지 확인 불가 -> 전송 속도가 중요하고, 일부 유실되어도
  무관한 데이터에 사용
- acks = 1(dafault)
  속도 보통, 유실 가능성 유
  프로듀서가 보낸 메시지가 리더 파티션에 정상 저장되었는지 확인, 팔로워 파티션에 저장되었는지 모름, 즉 리터 파티션에 저장되고 해당 브로커가 죽으면 데이터 유실 가능성 유,
- acls = -1
  속도 가장 느림, 메시지 전달 손실 가능성 없음
  프로듀서가 보낸 메시지가 리더, 팔로워 파티션에 정상 저장되었는지 확인, 리더 파티션의 데이터가 팔로워 파티션까지 복제될때까지 기다림.

# producer options

필수

- bootstrap.servers : 카프카 클러스터에 연ㅇ결하기 위한 브로커 목록
- key.serializer : 메시지 키 직렬화에 사용되는 클래스
- value.serializer : 메시지 값을 직렬화하는데 사용되는 클래스
  선택 - default 값 존재
- acks : 레코드 전송 신뢰도 조절
- comression.type :
- retries 클러스터 장애에 대응하여 메시지 전송 재시도 횟수
- buffer.memory :  브로커에 전송될 메시지의 버퍼로 사용될 메모리 양
- batch.size : 여러 데이터를 함께 보내기 위한 레코드 크기
- linger.ms : 현재의 배치를 전송하기 전까지 기다리는 시간
- client.id : 어떤 클라이언트인지 구분하는 식별자

# consumer

- 데이터를 가져가는 주체
- commit을 통해 읽은 consumer offset을 카프카에 기록한다.
- java kafka-client